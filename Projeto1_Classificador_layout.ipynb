{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Giovanni Rozatti\n",
    "\n",
    "Nome: Gabriel Parfan Guimarães"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\User\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\Desktop\\Insper\\2°Semestre DP\\CDados\\CD2020-Projeto1\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Produto escolhido: Atila Iamariano\n",
    "- Descrição do Produto: \n",
    "\n",
    "    Atila Iamarino (1984)é um biólogo e pesquisador brasileiro formado em microbiologia, possuindo também doutorado em virologia, notório por seu trabalho no canal de YouTube denominado \"Nerdologia\",que possui mais de 2 milhões de inscritos e integra o grupo Jovem Nerd, uma plataforma digital de cultura pop, jogos eletrônicos e conteúdo jovem. -Wikipedia  \n",
    "    \n",
    "    Átila já era bastante conhecido por seu canal no Youtube e por sua participação em podcasts, principalment do podcast Jovem Nerd) popularidade de Atila cresceu bastante atualmente, principalmente por conta do COVID-19, chegando a transmitir lives diárias, para falar da situação atual, cuidados preventivos e fazendo predições com uso de estatísticas e dados sobre como a situação se desdobraria, chegando a até mesmo a participar de um Programa do Roda-Viva `https://www.youtube.com/watch?v=s00BzYazxvU` - Observação de Giovanni Rozatti\n",
    "    ________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Método de classificação: \n",
    "foram realizados 2 níveis de classificação, no primeiro foi classificada a relêvancia da mensagem, e no segundo era avaliado o teor da mensagem\n",
    "___\n",
    "\n",
    "Nível 1 de classificação:\n",
    "\n",
    "- Relevante: Tweets que contribuiriam com o processo de classificação por estarem relacionados ou ao tema discutido ou a algo próximo e/ou que continham elementos possiveis para que fosse feita a classificação do teor de sua mensagem  \n",
    "    \n",
    "- Irrelevante: Tweets que não contribuiam com o processo de classificação e/ou não podiam ser classificados por falta de elementos que possibilitassem isso,como por exemplo: \"@atila que hrs são\" (esse tweet de fato apareeu na base de dados)  \n",
    "    \n",
    "- Opinião Política: Tweets que continham mensagens de teor político e/ou próximos a política explícitos, como por exemplo, os termos que apareceram com recorrencia considerável : \"bolsominion\" e \"comunista\"\n",
    "    \n",
    "Nesse nível as mensagens foram separadas nas três categorias acima, com o objetivo de fazer uma refiltragem dos tweets obtidos, originalmente seriam apenas duas categorias (Relevante e Irrelevante), no entanto ao decorrer do processo foi vista a necessidade de estender ainda mais esse escopo, isso possibilitará a classificação das mensagens excluindo as irrelevantes e as que possuem teor político, assim como a classificação excluindo apenas as irrelevantes nos fornecendo como resultado a resposta da pergunta:\n",
    "\"Quanto as mensagens com teor político influenciam de fato na classificação?\"\n",
    "___\n",
    "\n",
    "Nível 2 de classificação:\n",
    "\n",
    "\n",
    "- Classificações atribuidas e o que levou a atribuirmos fraases a elas:\n",
    "\n",
    "    - Show and tell: Tweets que em geral além de serem mensagens de apoiar/concordar, traziam perguntas, pesquisas, dados, materiais de referencia e fontes para embasamentos e reflexões, em geral continham teor similar ao dos exemplos a seguir: \"@oatila @maisalguem vocês viram isso?\", \"@atila, o que voce acha de...?\"  \n",
    "    \n",
    "    - Apoia/concorda: Tweets que em geral dizem: \"@oatila parabens pelo trabalho\", \"@oatila bacana essa info que você apresentou\"  \n",
    "    \n",
    "    - Discorda/Desacredita: Tweets que em geral fazem críticas ao trabalho feito, ou a uma posição que foi tomada, não necessariamente apresentando embasamento sobre o porque da crítica  \n",
    "    \n",
    "    - Mensagem de ódio:Tweets que apresentam mensagens ofensivas a esmo, (não necessáriamente ao biologo, mas ainda assim perinentes ao trabalho como será visto mais adiante nesse Notebook)*  \n",
    "    \n",
    "Nesse nível as mensagens foram separadas nas quatro categorias acima, com o objetivo de própriamente classificá-las para que pudessem passar pelo processo de slicing e classificação de palavras\n",
    "A classificação nessa parte foi feita de acordo com o seguinte método:   \n",
    "1. Se possível classificar como o classifiador Naive Bayes final do projeto faria, isso é analisar as palavras individualmente tentando prever o resultado da classificação.    \n",
    "2. Se não for possível classificar via método anterior classificar a frase como um todo de acordo com o teor que contém\n",
    "3. Se não for possível classificar de acordo com método anterior, marcar tweet como Irrelevante no nível de classificação 1**\n",
    "\n",
    "  $*$ Muitas das mensagens de ódio não estavam sendo direcionadas ao Biólogo mas a principalmente à @embaixadadachina e @mariuzakrause  \n",
    "  $**$Não hoveram casos em que o método 3 tenha sido utilizado\n",
    "\n",
    "   - @embaixadadachina:Trazendo a China para perto de você! Conta oficial da Embaixada da República Popular da China na República Federativa do Brasil. - bio no twitter da embaixada  \n",
    "        Foi alvo de várias mensagens de ódio falando principalmente:sobre sistema político-sócio-econômico chinês, e acusações de culpa pela disseminação do COVID-19, por conta de supostas alerações em estatísticas e por o vírus ser \"uma criação deles\"; A motivação dessas mensagens foi que o biólogo ter utilizado de pesquisas fornecidas pelo país\n",
    "\n",
    "   - @mariuzakrause: Direita, conservadora, bolsonariana, Jacobina, gado do Bolsonaro, Advogada nas horas vagas, petistas desapareçam! - bio no twitter de Mariuza  \n",
    "         Foi alvo de várias mensagens de ódio falando principalmente:sobre sua oientação política, autenticidade de sua formação em direito; A motivação dessas mensagens foi que mariuza discordou publiamente sobre o posicionamento do biólogo em relação a quarentena, chegando a difamá-lo em relação aos resultados obtidos através de algumas pesquisas dizendo que Átila estaria \"passando vergonha\"\n",
    "\n",
    "\n",
    "___\n",
    "- **Observação: a estrutura do código a seguir é similar ao do usado no meu trabalho no semestre anterior (perfil no git: VonIgnia), e pode ser visto em: `https://github.com/carolinechaim/Projeto_2/blob/master/NaiveBayes teste 1.ipynb` mais especificamente nos commits \"Planilha teste rodando no Jupyter\" e \"Planilha teste rodando os classificadores NaiveBayes\".**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lê as planilhas de treinamento\n",
    "training = pd.read_excel(\"@oatila1.xlsx\",sheet_name = 'Treinamento', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A função elimina tweets considerados como irrlevantes para o classificador\n",
    "\n",
    "#A variável Elimina recebe uma string pertencente a categoria Nivel de Relevancia \n",
    "#(\"Relevante\", \"Irrelevante\" e \"Opinião Política\")\n",
    "\n",
    "def Elimina_por_nível_de_relevância(train,Elimina):\n",
    "    for i in range(0, len(Elimina)):\n",
    "        train.drop(train[ train['Nível de relevância'] == Elimina[i].rstrip()].index, inplace=True)\n",
    "    return train\n",
    "\n",
    "#A função calcula as frequências relativas de cada categoria\n",
    "def Calcula_frequencias_relativas(train,relative):\n",
    "#Calcula as frequências relativas de cada categoria dentre o que foi considerado Relevante\n",
    "    probs = train[\"Opinião Pública\"].value_counts(relative,sort=False)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Apoio/Concorda          38\n",
       "Discorda/Desacredita    23\n",
       "Mensagem de ódio        31\n",
       "Show and tell           29\n",
       "Name: Opinião Pública, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lista de categorias a serem eliminadas\n",
    "Relev_Eliminate = ['Irrelevante']\n",
    "\n",
    "#chamando por outro nome para evitar o re-run de training\n",
    "#caso contrário training assumiria o valor do return da \n",
    "#função o que deixaria tudo mais complicado\n",
    "\n",
    "treino = Elimina_por_nível_de_relevância (training,Relev_Eliminate)\n",
    "Calcula_frequencias_relativas(treino,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'probs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-83c6d5ffed5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#essa célula não parece ter uilidade alguma -- analisar e posteriormente tomar uma decisão\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprob_OP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#Opinião Positiva\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprob_ON\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#Opinião Negativa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'probs' is not defined"
     ]
    }
   ],
   "source": [
    "#essa célula não parece ter uilidade alguma -- analisar e posteriormente tomar uma decisão\n",
    "prob_OP = probs[0] #Opinião Positiva\n",
    "prob_ON = probs[1] #Opinião Negativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separa todas as palavras que aparecem em cada categoria, não levando em conta repetições\n",
    "(caso uma palavra apareça mais de uma vez em uma mesma categoria, ela será contabilizada apenas uma vez naquela categoria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_classificações = treino[\"Opinião Pública\"].value_counts(sort=False).index.tolist()\n",
    "\n",
    "def Separa_palavras_em_series(train,lista_classificações):\n",
    "    series_categories=[]\n",
    "    for i in range(0,len(lista_classificações)):\n",
    "        category = train[train[\"Opinião Pública\"] == lista_classificações[i]]\n",
    "        category = category[\"Treinamento\"].str.cat().split()\n",
    "        series_categories.append(pd.Series(category))\n",
    "#====================================================================================================== \n",
    "    #-------------------------------------------------\n",
    "      ### tentativa (falha) de deixar o código genérico e portanto aplicável a qq objeto de estudo /n\n",
    "      ### para qq número de ccategorias, quaisquer que fosse sua ordem:\n",
    "    #------------\\/código das tentativas\\/--------------    \n",
    "        #for i in range(0,len(series_categories)):\n",
    "           # setattr('Series'+str(lista_classificações[i], 'foobar', series_categories[i])\n",
    "           # eval('Series'+str(lista_classificações[i]))series_categories[i]\n",
    "    #-------------------------------------------------\n",
    "#======================================================================================================    \n",
    "    return series_categories\n",
    "Separa_palavras_em_series(treino,lista_classificações)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Discorda = train[train[\"Opinião\"] == \"Discorda/Desacredita\"]\n",
    "Discorda = Discorda[\"Treinamento\"].str.cat().split()\n",
    "series_Discorda = pd.Series(ON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando uma \"tabela\" com a probabilidade individual de todas as palavras aparecerem em uma dada categoria\n",
    "(\"Dado que a opinião é essa qual a probabilidade dessa palavra aparecer?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_negativa = series_ON.value_counts(True)\n",
    "tabela_negativa;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_positiva = series_OP.value_counts(True)\n",
    "tabela_positiva;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando uma função que faz o calculo da frase pertencer a uma categoria utilizando a fórmula de bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificador_de_palavras_naive_bayes(tweet):\n",
    "    lista_palavras = tweet.split()\n",
    "    prob_positivo = 1\n",
    "    prob_negativo = 1\n",
    "    for palavra in lista_palavras:\n",
    "        \n",
    "        #Remove palavras iniciadas em @ para evitar viés\n",
    "        #vale ressaltar que há necessidade de se fazer isso \n",
    "        #pois muitas mensagens de ódio estavam direcionadas \n",
    "        #as strings @mariunakrauze e @ embaixadadachina\n",
    "        if palavra[0] == \"@\": \n",
    "            palavra = \" \"\n",
    "#----------------------------------------------------------------------------            \n",
    "        if palavra in tabela_negativa.index:\n",
    "            prob_palavra_negativa = tabela_negativa[palavra]\n",
    "        else:\n",
    "            prob_palavra_negativa = 1\n",
    "        if palavra in tabela_positiva.index:\n",
    "             prob_palavra_positivo = tabela_positiva[palavra]\n",
    "        else:\n",
    "             prob_palavra_positivo = 1\n",
    "        prob_negativo *= prob_palavra_negativa\n",
    "        prob_positivo *= prob_palavra_positivo\n",
    "        if (prob_negativo > prob_positivo):\n",
    "            return \"Negativo\"\n",
    "        else:\n",
    "            return \"Positivo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "leitura da planilha para testes com o classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_excel(\"Cinemark segunda 16-03.xlsx\",sheet_name = 'Teste', index = False).set_index(\"Teste\")\n",
    "lista_tweets = list(test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in lista_tweets:\n",
    "    test.loc[tweet,\"Classificação\"] = classificador_de_palavras_naive_bayes(tweet)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versão 1  (o objeto de clasificação ainda era Cinemark, mas como os erros daquela versão poderiam se repetir nessa e serviram para reflexões além de elaborações de uma maneira de \"consertá-los\".)\n",
    "22/03- o código roda mas claramente a classificação está com imperfeições isso pode se dar por:\n",
    " - erros de contabilização na fórmula do NaiveBayes\n",
    " - erros na clasificação do excel\n",
    " - certas palavras possuirem um viés deterministico mais forte para um dos lados (no caso a Opinião Positiva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
