{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Giovanni Rozatti\n",
    "\n",
    "Nome: Gabriel Parfan Guimarães"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\User\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\Desktop\\Insper\\2°Semestre DP\\CDados\\CD2020-Projeto1\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Produto escolhido: Atila Iamariano (@oatila)\n",
    "- Descrição do Produto: \n",
    "\n",
    "    Atila Iamarino (1984)é um biólogo e pesquisador brasileiro formado em microbiologia, possuindo também doutorado em virologia, notório por seu trabalho no canal de YouTube denominado \"Nerdologia\",que possui mais de 2 milhões de inscritos e integra o grupo Jovem Nerd, uma plataforma digital de cultura pop, jogos eletrônicos e conteúdo jovem. -Wikipedia  \n",
    "    \n",
    "    Átila já era bastante conhecido por seu canal no Youtube e por sua participação em podcasts, principalment do podcast Jovem Nerd) popularidade de Atila cresceu bastante atualmente, principalmente por conta do COVID-19, chegando a transmitir lives diárias, para falar da situação atual, cuidados preventivos e fazendo predições com uso de estatísticas e dados sobre como a situação se desdobraria, chegando a até mesmo a participar de um Programa do Roda-Viva `https://www.youtube.com/watch?v=s00BzYazxvU` - Observação de Giovanni Rozatti\n",
    "    ________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Método de classificação: \n",
    "foram realizados 2 níveis de classificação, no primeiro foi classificada a relêvancia da mensagem, e no segundo era avaliado o teor da mensagem\n",
    "___\n",
    "\n",
    "Nível 1 de classificação:\n",
    "\n",
    "- Relevante: Tweets que contribuiriam com o processo de classificação por estarem relacionados ou ao tema discutido ou a algo próximo e/ou que continham elementos possiveis para que fosse feita a classificação do teor de sua mensagem  \n",
    "    \n",
    "- Irrelevante: Tweets que não contribuiam com o processo de classificação e/ou não podiam ser classificados por falta de elementos que possibilitassem isso,como por exemplo: \"@atila que hrs são\" (esse tweet de fato apareeu na base de dados)  \n",
    "    \n",
    "- Opinião Política: Tweets que continham mensagens de teor político e/ou próximos a política explícitos, como por exemplo, os termos que apareceram com recorrencia considerável : \"bolsominion\" e \"comunista\"\n",
    "    \n",
    "Nesse nível as mensagens foram separadas nas três categorias acima, com o objetivo de fazer uma refiltragem dos tweets obtidos, originalmente seriam apenas duas categorias (Relevante e Irrelevante), no entanto ao decorrer do processo foi vista a necessidade de estender ainda mais esse escopo, isso possibilitará a classificação das mensagens excluindo as irrelevantes e as que possuem teor político, assim como a classificação excluindo apenas as irrelevantes nos fornecendo como resultado a resposta da pergunta:\n",
    "\"Quanto as mensagens com teor político influenciam de fato na classificação?\"\n",
    "___\n",
    "\n",
    "Nível 2 de classificação:\n",
    "\n",
    "\n",
    "- Classificações atribuidas e o que levou a atribuirmos fraases a elas:\n",
    "\n",
    "    - Show and tell: Tweets que em geral além de serem mensagens de apoiar/concordar, traziam perguntas, pesquisas, dados, materiais de referencia e fontes para embasamentos e reflexões, em geral continham teor similar ao dos exemplos a seguir: \"@oatila @maisalguem vocês viram isso?\", \"@atila, o que voce acha de...?\"  \n",
    "    \n",
    "    - Apoia/concorda: Tweets que em geral dizem: \"@oatila parabens pelo trabalho\", \"@oatila bacana essa info que você apresentou\"  \n",
    "    \n",
    "    - Discorda/Desacredita: Tweets que em geral fazem críticas ao trabalho feito, ou a uma posição que foi tomada, não necessariamente apresentando embasamento sobre o porque da crítica  \n",
    "    \n",
    "    - Mensagem de ódio:Tweets que apresentam mensagens ofensivas a esmo, (não necessáriamente ao biologo, mas ainda assim perinentes ao trabalho como será visto mais adiante nesse Notebook)*  \n",
    "    \n",
    "Nesse nível as mensagens foram separadas nas quatro categorias acima, com o objetivo de própriamente classificá-las para que pudessem passar pelo processo de slicing e classificação de palavras\n",
    "A classificação nessa parte foi feita de acordo com o seguinte método:   \n",
    "1. Se possível classificar como o classifiador Naive Bayes final do projeto faria, isso é analisar as palavras individualmente tentando prever o resultado da classificação.    \n",
    "2. Se não for possível classificar via método anterior classificar a frase como um todo de acordo com o teor que contém\n",
    "3. Se não for possível classificar de acordo com método anterior, marcar tweet como Irrelevante no nível de classificação 1**\n",
    "\n",
    "  $*$ Muitas das mensagens de ódio não estavam sendo direcionadas ao Biólogo mas a principalmente à @embaixadadachina e @mariuzakrause  \n",
    "  $**$Não hoveram casos em que o método 3 tenha sido utilizado\n",
    "\n",
    "   - @embaixadadachina:Trazendo a China para perto de você! Conta oficial da Embaixada da República Popular da China na República Federativa do Brasil. - bio no twitter da embaixada  \n",
    "        Foi alvo de várias mensagens de ódio falando principalmente:sobre sistema político-sócio-econômico chinês, e acusações de culpa pela disseminação do COVID-19, por conta de supostas alerações em estatísticas e por o vírus ser \"uma criação deles\"; A motivação dessas mensagens foi que o biólogo ter utilizado de pesquisas fornecidas pelo país\n",
    "\n",
    "   - @mariuzakrause: Direita, conservadora, bolsonariana, Jacobina, gado do Bolsonaro, Advogada nas horas vagas, petistas desapareçam! - bio no twitter de Mariuza  \n",
    "         \n",
    "        Foi alvo de várias mensagens de ódio falando principalmente:sobre sua oientação política, autenticidade de sua formação em direito; A motivação dessas mensagens foi que mariuza discordou publiamente sobre o posicionamento do biólogo em relação a quarentena, chegando a difamá-lo em relação aos resultados obtidos através de algumas pesquisas dizendo que Átila estaria \"passando vergonha\"\n",
    "\n",
    "\n",
    "___\n",
    "<font color=#EF3333> - **Observação: a estrutura do código a seguir é similar ao do usado no meu trabalho no semestre anterior (perfil no git: VonIgnia), e pode ser visto em: `https://github.com/carolinechaim/Projeto_2/blob/master/NaiveBayes teste 1.ipynb` mais especificamente nos commits \"Planilha teste rodando no Jupyter\" e \"Planilha teste rodando os classificadores NaiveBayes\".**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lê as planilhas de treinamento\n",
    "training = pd.read_excel(\"@oatila1.xlsx\",sheet_name = 'Treinamento', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A função elimina tweets considerados como irrlevantes para o classificador\n",
    "\n",
    "#A variável Elimina recebe uma string pertencente a categoria Nivel de Relevancia \n",
    "#(\"Relevante\", \"Irrelevante\" e \"Opinião Política\")\n",
    "\n",
    "def Elimina_por_nível_de_relevância(train,Elimina):\n",
    "    for i in range(0, len(Elimina)):\n",
    "        train.drop(train[ train['Nível de relevância'] == Elimina[i].rstrip()].index, inplace=True)\n",
    "    return train\n",
    "\n",
    "#A função calcula as frequências relativas de cada categoria\n",
    "def Calcula_frequencias_relativas(train,relative):\n",
    "#Calcula as frequências relativas de cada categoria dentre o que foi considerado Relevante\n",
    "    probs = train[\"Opinião Pública\"].value_counts(relative,sort=False)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Apoio/Concorda          38\n",
       "Discorda/Desacredita    23\n",
       "Mensagem de ódio        31\n",
       "Show and tell           29\n",
       "Name: Opinião Pública, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lista de categorias a serem eliminadas\n",
    "Relev_Eliminate = ['Irrelevante']\n",
    "\n",
    "#chamando por outro nome para evitar o re-run de training /n\n",
    "#caso contrário training assumiria o valor do return da /n\n",
    "#função o que deixaria tudo mais complicado\n",
    "\n",
    "treino = Elimina_por_nível_de_relevância (training,Relev_Eliminate)\n",
    "Calcula_frequencias_relativas(treino,False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separa todas as palavras que aparecem em cada categoria no formato de uma Série"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Separa_palavras_em_series(train,lista_classificações):\n",
    "    series_categories=[]\n",
    "    for i in range(0,len(lista_classificações)):\n",
    "        category = train[train[\"Opinião Pública\"] == lista_classificações[i]]\n",
    "        category = category[\"Treinamento\"].str.cat().split()\n",
    "        series_categories.append(pd.Series(category))\n",
    "#====================================================================================================== \n",
    "    #-------------------------------------------------\n",
    "      ### tentativa (falha) de deixar o código genérico e portanto aplicável a qq objeto de estudo /n\n",
    "      ### para qq número de ccategorias, quaisquer que fosse sua ordem:\n",
    "    #------------\\/código das tentativas\\/--------------    \n",
    "        #for i in range(0,len(series_categories)):\n",
    "           # setattr('Series'+str(lista_classificações[i], 'foobar', series_categories[i])\n",
    "           # eval('Series'+str(lista_classificações[i]))series_categories[i]\n",
    "    #-------------------------------------------------\n",
    "#======================================================================================================    \n",
    "    return series_categories\n",
    "lista_classificações = treino[\"Opinião Pública\"].value_counts(sort=False).index.tolist()\n",
    "series_categorias = Separa_palavras_em_series(treino,lista_classificações) #Uma lista de 4 series;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isso só pode ser feito quando Sort=False e quando a ordem,/n\n",
    "#é conhecida caso contrário pode criar erros no classificador\n",
    "series_Apoia    = pd.Series(series_categorias[0])\n",
    "series_Discorda = pd.Series(series_categorias[1])\n",
    "series_Odeia    = pd.Series(series_categorias[2])\n",
    "series_Mostra   = pd.Series(series_categorias[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando uma \"tabela\" com a probabilidade individual de todas as palavras aparecerem em uma dada categoria\n",
    "(\"Dado que a opinião é essa qual a probabilidade dessa palavra aparecer?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_Apoia    = series_Apoia.value_counts(True)\n",
    "tabela_Discorda = series_Discorda.value_counts(True)\n",
    "tabela_Odeia    = series_Odeia.value_counts(True)\n",
    "tabela_Mostra   = series_Mostra.value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Raptando\" a função de limpeza de pontuações e sinais do notebook da aula 7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    #punctuation = '[!-.:?;\")(]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    punctuation =\"['(',')','\"',\"'\",',','.',':']\"\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A  definição  de  insanidade  é  fazer a  mesma coisa /n repetidamente e esperar resultados diferentes '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exemplo1='A (definição) de \"insanidade\" é. fazer a, mesma coisa /n repetidamente e esperar resultados diferentes.'\n",
    "cleanup(exemplo1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando uma função que faz o calculo da frase pertencer a uma categoria utilizando a fórmula de bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpeza_total(tweet):\n",
    "    cleanup(tweet)\n",
    "    lista_palavras = tweet.split()\n",
    "\n",
    "    for palavra in lista_palavras:\n",
    "        \n",
    "        if palavra == \"\\n\":\n",
    "            palavra == \" \"       \n",
    "#----------------------------------------------------------------------------        \n",
    "    #caso tenha uma palavra \"colada\" a um @ esse /n\n",
    "    #for separa a parte pré @ e pós @, através da /n\n",
    "    #inserção de um espaço vazio entre elas\n",
    "        for i in range(0,len(palavra)):\n",
    "            if palavra[i] == \"@\":\n",
    "                palavra[i].replace(\"@\", \" @\")\n",
    "#----------------------------------------------------------------------------    \n",
    "    #Remove palavras iniciadas em @ para evitar viés\n",
    "    #vale ressaltar que há necessidade de se fazer isso \n",
    "    #pois muitas mensagens de ódio estavam direcionadas \n",
    "    #as strings @mariunakrauze e @ embaixadadachina               \n",
    "        if palavra[0] == \"@\": \n",
    "            palavra = \" \"\n",
    "#----------------------------------------------------------------------------            \n",
    "return(lista_palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificador_de_palavras_multinomial_naive_bayes(tweet):   \n",
    "    prob_Apoia = 1\n",
    "    prob_Discorda = 1\n",
    "    prob_Odeia = 1\n",
    "    prob_Mostra = 1\n",
    "    \n",
    "#===========================================================    \n",
    "    #---------------------------------------------------\n",
    "    if palavra in tabela_negativa.index:\n",
    "        prob_palavra_Apoia = tabela_Apoia[palavra]\n",
    "    else:\n",
    "        prob_palavra_Apoia = 1\n",
    "    #---------------------------------------------------    \n",
    "    if palavra in tabela_negativa.index:\n",
    "        prob_palavra_Discorda = tabela_Discorda[palavra]\n",
    "    else:\n",
    "        prob_palavra_Discorda = 1\n",
    "    #---------------------------------------------------\n",
    "        if palavra in tabela_negativa.index:\n",
    "        prob_palavra_Odeia = tabela_Odeia[palavra]\n",
    "    else:\n",
    "        prob_palavra_Odeia = 1\n",
    "    #---------------------------------------------------\n",
    "        if palavra in tabela_negativa.index:\n",
    "        prob_palavra_Mostra = tabela_Mostra[palavra]\n",
    "    else:\n",
    "        prob_palavra_Mostra = 1\n",
    "    #---------------------------------------------------\n",
    "#===========================================================    \n",
    "   \n",
    "    prob_Apoia *= prob_palavra_Apoia\n",
    "    prob_Discorda *= prob_palavra_Discorda\n",
    "    prob_Odeia *= prob_palavra_Odeia\n",
    "    prob_Mostra *= prob_palavra_Mostra\n",
    "    \n",
    "#===========================================================    \n",
    "\n",
    "        if (prob_negativo > prob_positivo):\n",
    "            return \"Negativo\"\n",
    "        else:\n",
    "            return \"Positivo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "leitura da planilha para testes com o classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_excel(\"Cinemark segunda 16-03.xlsx\",sheet_name = 'Teste', index = False).set_index(\"Teste\")\n",
    "lista_tweets = list(test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in lista_tweets:\n",
    "    test.loc[tweet,\"Classificação\"] = classificador_de_palavras_naive_bayes(tweet)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versão 1  (o objeto de clasificação ainda era Cinemark, mas como os erros daquela versão poderiam se repetir nessa e serviram para reflexões além de elaborações de uma maneira de \"consertá-los\".)\n",
    "22/03- o código roda mas claramente a classificação está com imperfeições isso pode se dar por:\n",
    " - erros de contabilização na fórmula do NaiveBayes\n",
    " - erros na clasificação do excel\n",
    " - certas palavras possuirem um viés deterministico mais forte para um dos lados (no caso a Opinião Positiva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis  --check--\n",
    "* Corrigir separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação \n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
